{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Reshape, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.encoder_model = None\n",
    "        self.model = None\n",
    "        return\n",
    "    \n",
    "    def build(self, input_dims, opt):\n",
    "        input_layer = Input(shape=input_dims)\n",
    "        \n",
    "        a_one = Conv2D(64, (3,3), activation='relu', padding='same') (input_layer)\n",
    "        #a_two = BatchNormalization() (a_one)\n",
    "        a_three = Conv2D(64, (3,3), activation='relu', padding='same') (a_one)\n",
    "        #a_four = BatchNormalization() (a_three)\n",
    "        a_five = MaxPooling2D() (a_three)\n",
    "        block_one = Dropout(0.25) (a_five)\n",
    "        #block_one = a_five\n",
    "        \n",
    "        b_one = Conv2D(128, (3,3), activation='relu', padding='same') (block_one)\n",
    "        #b_two = BatchNormalization() (b_one)\n",
    "        b_three = Conv2D(128, (3,3), activation='relu', padding='same') (b_one)\n",
    "        #b_four = BatchNormalization() (b_two)\n",
    "        b_five = MaxPooling2D() (b_three)\n",
    "        block_two = Dropout(0.25) (b_five)\n",
    "        \n",
    "        c_one = Conv2D(256, (3,3), activation='relu', padding='same') (block_two)\n",
    "        #c_two = BatchNormalization() (c_one)\n",
    "        c_three = Conv2D(256, (3,3), activation='relu', padding='same') (c_one)\n",
    "        #c_four = BatchNormalization() (c_three)\n",
    "        c_five = MaxPooling2D() (c_three)\n",
    "        block_three = Dropout(0.5) (c_five)\n",
    "        \n",
    "        d_one = Conv2D(512, (3,3), activation='relu', padding='same') (block_three)\n",
    "        #d_two = BatchNormalization() (d_one)\n",
    "        d_three = Conv2D(512, (1,1), activation='relu', padding='same') (d_one)\n",
    "        #d_four = BatchNormalization() (d_three)\n",
    "        d_five = MaxPooling2D() (d_three)\n",
    "        block_four = Dropout(0.2) (d_five)\n",
    "        \n",
    "        flat = Flatten() (block_four)\n",
    "        fc_one = Dense(4096, activation='relu') (flat)\n",
    "        #block_five = BatchNormalization() (fc_one)\n",
    "        \n",
    "        fc_two = Dense(4096, activation='relu') (fc_one)\n",
    "        #block_six = BatchNormalization() (fc_two)\n",
    "        \n",
    "        final = Dense(4, activation='softmax') (fc_two)\n",
    "        \n",
    "        self.model = Model(input_layer, final)\n",
    "        self.feature_extractor = Model(input_layer, flat)\n",
    "        self.model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return\n",
    "    \n",
    "    def load(self, model_file, encoder_model_file):\n",
    "        self.encoder_model = load_model(encoder_model_file)\n",
    "        self.model = load_model(model_file)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_input, train_output,\n",
    "             val_input, val_output,\n",
    "             epochs=50,\n",
    "             batch_size=64,\n",
    "             shuffle=True):\n",
    "        tensorboard = TensorBoard(log_dir='./tf_logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "        self.model.fit(train_input, train_output,\n",
    "                      epochs=epochs, batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      validation_data=(val_input, val_output),\n",
    "                      callbacks=[tensorboard])\n",
    "        return\n",
    "    \n",
    "    def encoder_predict(self, test_input):\n",
    "        return self.encoder_model.predict(test_input)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        return self.model.predict(test_input)\n",
    "    \n",
    "    def save(self, model_file, encoder_model_file):\n",
    "        self.model.save(model_file)\n",
    "        self.encoder_model.save(encoder_model_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "interested = [0, 1, 8, 9]\n",
    "\n",
    "scrap = []\n",
    "for idx, im in enumerate(x_train):\n",
    "    if (y_train[idx][0] not in interested):\n",
    "        scrap.append(idx)\n",
    "        \n",
    "x_train = np.delete(x_train, scrap, axis=0)\n",
    "y_train = np.delete(y_train, scrap, axis=0)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "y_train = enc.transform(y_train).toarray()\n",
    "\n",
    "scrap = []\n",
    "for idx, im in enumerate(x_test):\n",
    "    if (y_test[idx][0] not in interested):\n",
    "        scrap.append(idx)\n",
    "x_test = np.delete(x_test, scrap, axis=0)\n",
    "y_test = np.delete(y_test, scrap, axis=0)\n",
    "y_test = enc.transform(y_test).toarray()\n",
    "\n",
    "x_train = (x_train.astype('float32')) / 255.0\n",
    "x_test = (x_test.astype('float32')) / 255.0\n",
    "\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()\n",
    "opt = optimizers.adam(lr=0.0001, decay=1e-6)\n",
    "#opt = optimizers.rmsprop()\n",
    "#opt = optimizers.SGD(lr=0.1, nesterov=True, momentum=0.9)\n",
    "fe.build((32, 32, 3, ), opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.train(x_train, y_train, x_test, y_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=128,\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.save('extractor.h5', 'extractor-model.h5')\n",
    "print \"Model saved!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
